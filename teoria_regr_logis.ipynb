{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teoría Regresión Logística\n",
    "\n",
    "Es un modelo de clasificación de machine learning los cuales comprende: __Regresión Logística Binaria__, __Ordenada__ y __Multinomial__. Todas comparten la sigueinte función de enlace __logit__.\n",
    "$$ log_{e}\\left ( \\frac{p}{1-p} \\right )$$\n",
    "\n",
    "donde __p__ es alguna probabilidad.\n",
    "\n",
    "Para la regresión logistica binaria y multinomial, se podría escribir las probabilidades como:\n",
    "$$ log_{e}\\left ( \\frac{P(Y=j|X)}{P(Y=M + 1|X)} \\right )$$\n",
    "para __j__ en 1,.....,__M__. \n",
    "\n",
    "Donde __M__ + 1 corresponde a los niveles discretos del ejercicio. En el caso __binario__, hay 2 niveles (__M__ = 1 y __M__=2).\n",
    "\n",
    " Sabemos muy bien que la suma de las probabilidades debe ser 1.\n",
    "\n",
    "$$ \\sum_{j=1}^{M+1}P(Y=j|X)=1$$\n",
    "\n",
    "Por tanto, la expresión __logit__ para resultados binarios se simplifica.\n",
    "$$log_{e}\\left ( \\frac{P(Y=1|X)}{1-P(Y=1|X)} \\right )$$\n",
    "\n",
    "Para la regresión logistica __ordenada__, es estandar utilizar un __logit acumulativo__, que tiene la siguiente forma:\n",
    "\n",
    "$$log_{e}\\left ( \\frac{P(Y \\leq j|X)}{1-P(Y\\leq j|X)} \\right )$$\n",
    "\n",
    "La relación de probabilidades se conoce como __ODDS__:\n",
    "$$Odds = \\left ( \\frac{P(Y =1|X)}{1-P(Y=1|X)} \\right )$$\n",
    "\n",
    "Por ejemplo, con $P(Y=1|X)=0.75$, se tiene lo siguiente:\n",
    "$$Odds = \\frac{0.75}{1-0.75} =\\frac{0.75}{0.25}= 3$$\n",
    "La interpretación sería: \"Se espera que tenga 3 veces más de probabilidades de tener el evento (__Y=1__), que no tener el evento (__Y=0__). El __logit__ es el algoritmo de las probabilidades.\n",
    "\n",
    "Los coeficientes de la regresión se basan en las probabilidades. \n",
    "\n",
    "Tomando el caso más simple; un modelo con un solo predictor $x_{1}$:\n",
    "\n",
    "$$ log_{e}\\left ( \\frac{P(Y_{i}=1|X=x_{1i})}{1-P(Y_{i}=1|X =x_{1i})} \\right )= \\beta_{0}+ \\beta_{1}*x_{1i}$$\n",
    "\n",
    "El coeficiente $\\beta_{1}$, se define: \n",
    "$$ \\beta _{1}=log_{e}\\left ( \\frac{P(Y_{i}=1|X=x_{1i}+1)}{P(Y_{i}=1|X =x_{1i})} \\right )= \\beta_{0}+ \\beta_{1}*x_{1i}$$\n",
    "\n",
    "Es una practica comun reportar las __razones de probabilidades__ en lugar de las __razones de probabilidades logaritmicas__, lo cual se logra exponenciando los coeficientes.\n",
    "\n",
    "$$ OddsRatio = OR = e ^{\\beta _{1}} $$\n",
    "\n",
    "\n",
    "Suponiendo que $\\beta_{1}$ = 0.5, entonces $e ^{0.5}$=1.65; se interpretaria como una indicación de que un cambio en un unidad en $x_{1}$, se asoció con __1.65 veces__ la probabilidad de obtener el evento.\n",
    "\n",
    "A diferencia de las probabilidades (que tienen una interpretacion bastante natural), los coeficientes de probabilidades son un poco más dificiles de interpretar, ya que representan un __cambio multiplicativo en las probabilidades__, pero no indican cuales eran las probabilidades."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
